{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# CSE 258 - HW 3\n",
    "Jin Dai / A92408103"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task (Rating prediction)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import copy\n",
    "import gzip\n",
    "import math\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import tensorflow as tf\n",
    "import csv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def read_gz(path):\n",
    "    for l in gzip.open(path, 'rt'):\n",
    "        yield eval(l)\n",
    "\n",
    "def read_csv(path):\n",
    "    f = gzip.open(path, 'rt')\n",
    "    c = csv.reader(f)\n",
    "    header = next(c)\n",
    "    print(header)\n",
    "    for l in c:\n",
    "        yield l"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['user_id', 'recipe_id', 'date', 'rating']\n"
     ]
    },
    {
     "data": {
      "text/plain": "[['88348277', '03969194', '2004-12-23', '5'],\n ['86699739', '27096427', '2002-01-12', '4']]"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = list(read_csv(\"trainInteractions.csv.gz\"))\n",
    "dataset[:2]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 9."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "userIDs = {}\n",
    "itemIDs = {}\n",
    "interactions = []\n",
    "\n",
    "for d in dataset:\n",
    "    u = d[0]\n",
    "    i = d[1]\n",
    "    r = int(d[3])\n",
    "    if not u in userIDs: userIDs[u] = len(userIDs)\n",
    "    if not i in itemIDs: itemIDs[i] = len(itemIDs)\n",
    "    interactions.append((u,i,r))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "500000"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.shuffle(interactions)\n",
    "len(interactions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "nTrain = 400000\n",
    "data_train = interactions[:nTrain]\n",
    "data_valid = interactions[nTrain:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "itemsPerUser = defaultdict(list)\n",
    "usersPerItem = defaultdict(list)\n",
    "for u,i,r in data_train:\n",
    "    itemsPerUser[u].append(i)\n",
    "    usersPerItem[i].append(u)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "mu = sum([r for _,_,r in data_train]) / len(data_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "class LatentFactorModelBiasOnly(tf.keras.Model):\n",
    "    def __init__(self, mu, lamb):\n",
    "        super(LatentFactorModelBiasOnly, self).__init__()\n",
    "        # Initialize to average\n",
    "        self.alpha = tf.Variable(mu)\n",
    "        # Initialize to small random values\n",
    "        self.betaU = tf.Variable(tf.random.normal([len(userIDs)],stddev=0.001))\n",
    "        self.betaI = tf.Variable(tf.random.normal([len(itemIDs)],stddev=0.001))\n",
    "        self.lamb = lamb\n",
    "\n",
    "    # Prediction for a single instance (useful for evaluation)\n",
    "    def predict(self, u, i):\n",
    "        p = tf.Variable(self.alpha)\n",
    "        if 0 <= u < self.betaU.shape[0]:\n",
    "            p.assign_add(self.betaU[u])\n",
    "        if 0 <= i < self.betaI.shape[0]:\n",
    "            p.assign_add(self.betaI[i])\n",
    "        return p\n",
    "\n",
    "    # Regularizer\n",
    "    def reg(self):\n",
    "        return self.lamb * (tf.reduce_sum(self.betaU**2)\n",
    "                            + tf.reduce_sum(self.betaI**2))\n",
    "\n",
    "    # Prediction for a sample of instances\n",
    "    def predictSample(self, sampleU, sampleI):\n",
    "        u = tf.convert_to_tensor(sampleU, dtype=tf.int32)\n",
    "        i = tf.convert_to_tensor(sampleI, dtype=tf.int32)\n",
    "        beta_u = tf.nn.embedding_lookup(self.betaU, u)\n",
    "        beta_i = tf.nn.embedding_lookup(self.betaI, i)\n",
    "        pred = self.alpha + beta_u + beta_i\n",
    "        return pred\n",
    "\n",
    "    # Loss\n",
    "    def call(self, sampleU, sampleI, sampleR):\n",
    "        pred = self.predictSample(sampleU, sampleI)\n",
    "        r = tf.convert_to_tensor(sampleR, dtype=tf.float32)\n",
    "        return tf.nn.l2_loss(pred - r) / len(sampleR)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def trainingStepBiasOnly(model, interactions, optimizer):\n",
    "    Nsamples = 50000\n",
    "    with tf.GradientTape() as tape:\n",
    "        sampleU, sampleI, sampleR = [], [], []\n",
    "        for _ in range(Nsamples):\n",
    "            u,i,r = random.choice(interactions)\n",
    "            sampleU.append(userIDs[u])\n",
    "            sampleI.append(itemIDs[i])\n",
    "            sampleR.append(r)\n",
    "\n",
    "        loss = model(sampleU,sampleI,sampleR)\n",
    "        loss += model.reg()\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients((grad, var) for\n",
    "        (grad, var) in zip(gradients, model.trainable_variables)\n",
    "        if grad is not None)\n",
    "    return loss.numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def fit(data_train, mu, lamb=1, learning_rate=0.001, print_log=False):\n",
    "    model = LatentFactorModelBiasOnly(mu, lamb)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    min_obj = math.inf\n",
    "    best_model = copy.deepcopy(model)\n",
    "    counter = 0\n",
    "    while counter < 200:\n",
    "        local_obj = trainingStepBiasOnly(model, data_train, optimizer)\n",
    "        if print_log and counter % 10 == 0:\n",
    "            print(\"iteration %d, objective = %f, min_obj=%f\" % (counter, local_obj, min_obj))\n",
    "        if local_obj < min_obj:\n",
    "            min_obj = local_obj\n",
    "            best_model = copy.deepcopy(model)\n",
    "        counter += 1\n",
    "    return best_model, min_obj"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def MSE(pred, y):\n",
    "    differences = [(x-y)**2 for x,y in zip(pred,y)]\n",
    "    return sum(differences) / len(differences)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0, objective = 0.609791, min_obj=inf\n",
      "iteration 10, objective = 0.458401, min_obj=0.473227\n",
      "iteration 20, objective = 0.453397, min_obj=0.450814\n",
      "iteration 30, objective = 0.446109, min_obj=0.445760\n",
      "iteration 40, objective = 0.444509, min_obj=0.441185\n",
      "iteration 50, objective = 0.453136, min_obj=0.441185\n",
      "iteration 60, objective = 0.447732, min_obj=0.440643\n",
      "iteration 70, objective = 0.441606, min_obj=0.440643\n",
      "iteration 80, objective = 0.440891, min_obj=0.437924\n",
      "iteration 90, objective = 0.438580, min_obj=0.434747\n",
      "iteration 100, objective = 0.456176, min_obj=0.430425\n",
      "iteration 110, objective = 0.451166, min_obj=0.430425\n",
      "iteration 120, objective = 0.450597, min_obj=0.430425\n",
      "iteration 130, objective = 0.456477, min_obj=0.430425\n",
      "iteration 140, objective = 0.461755, min_obj=0.429986\n",
      "iteration 150, objective = 0.442673, min_obj=0.429986\n",
      "iteration 160, objective = 0.447112, min_obj=0.429986\n",
      "iteration 170, objective = 0.449068, min_obj=0.429986\n",
      "iteration 180, objective = 0.449690, min_obj=0.429986\n",
      "iteration 190, objective = 0.450194, min_obj=0.429986\n",
      "Min objective has been reached at 0.429986.\n"
     ]
    }
   ],
   "source": [
    "modelBiasOnly, min_obj = fit(data_train, mu, print_log=True)\n",
    "print(\"Min objective has been reached at %f.\" % min_obj)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def predict(model, user, item):\n",
    "    u = userIDs[user] if user in userIDs else -1\n",
    "    i = itemIDs[item] if item in itemIDs else -1\n",
    "    return model.predict(u, i).numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "pred = [predict(modelBiasOnly, u,i) for u,i,_ in data_valid]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "y_valid = [r for _,_,r in data_valid]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9110000589935944"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE(pred, y_valid)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 10."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=float32, numpy=1.5287205e-06>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelBiasOnly.betaI[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "('53280340', '99980672', 4)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "init_betaI = float(modelBiasOnly.betaI[0])\n",
    "init_betaU = float(modelBiasOnly.betaU[0])\n",
    "init_I, init_U, _ = interactions[0]\n",
    "max_betaI = init_betaI\n",
    "max_I = init_I\n",
    "min_betaI = init_betaI\n",
    "min_I = init_I\n",
    "max_betaU = init_betaU\n",
    "max_U = init_U\n",
    "min_betaU = init_betaU\n",
    "min_U = init_U"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "for usr, index in userIDs.items():\n",
    "    beta_u = modelBiasOnly.betaU[index]\n",
    "    if beta_u > max_betaU:\n",
    "        max_betaU = beta_u\n",
    "        max_U = usr\n",
    "    if beta_u < min_betaU:\n",
    "        min_betaU = beta_u\n",
    "        min_U = usr\n",
    "\n",
    "for item, index in itemIDs.items():\n",
    "    beta_i = modelBiasOnly.betaI[index]\n",
    "    if beta_i > max_betaI:\n",
    "        max_betaI = beta_i\n",
    "        max_I = item\n",
    "    if beta_i < min_betaI:\n",
    "        min_betaI = beta_i\n",
    "        min_I = item"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User '32445558' has the largest betaU: 0.001695\n",
      "User '70705426' has the smallest betaU: -0.000648\n",
      "Recipe '17799621' has the largest betaI: 0.000196\n",
      "Recipe '74912490' has the smallest betaI: -0.000361\n"
     ]
    }
   ],
   "source": [
    "print(\"User \\'%s\\' has the largest betaU: %f\" % (max_U, max_betaU))\n",
    "print(\"User \\'%s\\' has the smallest betaU: %f\" % (min_U, min_betaU))\n",
    "print(\"Recipe \\'%s\\' has the largest betaI: %f\" % (max_I, max_betaI))\n",
    "print(\"Recipe \\'%s\\' has the smallest betaI: %f\" % (min_I, min_betaI))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 11."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min objective has reached at 0.425581 with lambda=2.000000. MSE on validation set: 0.911024.\n",
      "Min objective has reached at 0.429982 with lambda=1.000000. MSE on validation set: 0.911018.\n",
      "Min objective has reached at 0.433401 with lambda=0.100000. MSE on validation set: 0.910442.\n",
      "Min objective has reached at 0.426937 with lambda=0.010000. MSE on validation set: 0.905963.\n",
      "Min objective has reached at 0.421587 with lambda=0.001000. MSE on validation set: 0.891642.\n",
      "Min objective has reached at 0.410917 with lambda=0.000100. MSE on validation set: 0.873868.\n",
      "Min objective has reached at 0.391931 with lambda=0.000010. MSE on validation set: 0.864338.\n",
      "Min objective has reached at 0.392097 with lambda=0.000001. MSE on validation set: 0.868307.\n"
     ]
    }
   ],
   "source": [
    "hp_lambdas = [2, 1, 0.1, 0.01, 0.001, 0.0001, 0.00001, 0.000001]\n",
    "min_MSE = math.inf\n",
    "best_lamb = 1\n",
    "best_model = modelBiasOnly\n",
    "for l in hp_lambdas:\n",
    "    model, min_obj = fit(data_train, mu, lamb=l)\n",
    "    pred = [predict(model, u,i) for u,i,_ in data_valid]\n",
    "    mse = MSE(pred, y_valid)\n",
    "    print(\"Min objective has reached at %f with lambda=%f. MSE on validation set: %f.\" % (min_obj, l, mse))\n",
    "    if mse < min_MSE:\n",
    "        min_MSE = mse\n",
    "        best_lamb = l\n",
    "        best_model = model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When we set lambda to 0.000010, the model performs better and yields min MSE=0.864338\n"
     ]
    }
   ],
   "source": [
    "print('When we set lambda to %f, the model performs better and yields min MSE=%f' % (best_lamb, min_MSE))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "predictions = open(\"predictions_Rated.txt\", 'w')\n",
    "for l in open(\"stub_Rated.txt\"):\n",
    "    if l.startswith(\"user_id\"):\n",
    "        #header\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,i = l.strip().split('-')\n",
    "    predictions.write(u + '-' + i + ',' + str(predict(best_model, u, i)) + '\\n')\n",
    "predictions.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Kaggle Username: Jin Dai"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}